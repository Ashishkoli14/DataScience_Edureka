{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcT3pgZ8F5vZ"
   },
   "source": [
    "## Day 47- DIY Solution\n",
    "**Q1. Problem Statement: Sentiment Analysis**<br>\n",
    "Write a Python program that reads the mood_data.txt (provided on LMS). The following are the given tasks, that has to be taken into\n",
    "consideration while constructing the solution.<br>\n",
    "Here dataset contains two columns where one is our target (“emotion” has 6\n",
    "different categories) and another is the independent variable (“Text” contains\n",
    "data in form of sentences).\n",
    "1. Load the mobile mood_data.txt data into a DataFrame\n",
    "2. Generate tokens and remove punctuations, stop words and lower all rows\n",
    "3. Join all the tokens as they were before and store them in a new column named\n",
    "“cleaned_text”\n",
    "4. Now remove all single characters, extra space, and special characters and\n",
    "store processed data in a new column named “processed_text”\n",
    "5. Create a final DataFrame containing dependent variable(emotion) and\n",
    "processed text\n",
    "6. Extract independent variables (Xs) and dependent variables (Ys) into separate\n",
    "data objects\n",
    "7. Generate tokens and do vectorization\n",
    "\n",
    "8. Build a model with Multinomial Naive Bayes, Random Forest, Random Forest (Entr\n",
    "opy), SVM and compare their accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhBr7mwMF5vf",
    "outputId": "ede2f4a4-8658-45ff-bd1b-9c4abd154cfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4ra32YQG9U5"
   },
   "source": [
    "**Step-1:** Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7EKDoxP5F5vh"
   },
   "outputs": [],
   "source": [
    "# Load the required libraries from Python\n",
    "# Make sure all the libraries have been download else download using nltk.download command\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o_vuZ60F5vi"
   },
   "source": [
    "**Step-2:** Loading sample data set into dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KDhBoFDyF5vi"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('mood_data.txt', names=['Text', 'Emotion'], sep=';') # load the dataset onto the google colab file section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BOpsMZeUF5vj",
    "outputId": "e41ae291-149f-4ef3-99f3-0b2f9a30f67b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eBEaigF6F5vk",
    "outputId": "0257e165-fb54-40f6-cdf0-7169074c9315"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Emotion\n",
       "0                            i didnt feel humiliated  sadness\n",
       "1  i can go from feeling so hopeless to so damned...  sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger\n",
       "3  i am ever feeling nostalgic about the fireplac...     love\n",
       "4                               i am feeling grouchy    anger"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0EO-sCyF5vk"
   },
   "source": [
    "**Step-3:** Generating tokens and remove punctuations, stop words and converting all rows to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZJbaEX2XF5vl"
   },
   "outputs": [],
   "source": [
    "# Load the required libraries for cleaning\n",
    "import string,re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "E7SISoiDF5vm"
   },
   "outputs": [],
   "source": [
    "# Create a function to generate cleaned data from raw text\n",
    "def clean_text(mood):\n",
    "    mood = word_tokenize(mood) # Create tokens\n",
    "    mood= \" \".join(mood) # Join tokens\n",
    "    mood = [char for char in mood if char not in string.punctuation] # Remove punctuations\n",
    "    mood = ''.join(mood) # Join the leters\n",
    "    mood = [word for word in mood.split() if mood.lower() not in stopwords.words('english')] # Remove common english words (I, you, we,...)\n",
    "    return \" \".join(mood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weZ8ojONF5vm"
   },
   "source": [
    "**Step-4:** Storing new data in cleaned_text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "1RPKbPwLF5vm",
    "outputId": "601e1224-31d5-4615-b28d-951c22f0b688"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "      <td>i feel strong and good overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion  \\\n",
       "0                                i didnt feel humiliated  sadness   \n",
       "1      i can go from feeling so hopeless to so damned...  sadness   \n",
       "2       im grabbing a minute to post i feel greedy wrong    anger   \n",
       "3      i am ever feeling nostalgic about the fireplac...     love   \n",
       "4                                   i am feeling grouchy    anger   \n",
       "...                                                  ...      ...   \n",
       "15995  i just had a very brief time in the beanbag an...  sadness   \n",
       "15996  i am now turning and i feel pathetic that i am...  sadness   \n",
       "15997                     i feel strong and good overall      joy   \n",
       "15998  i feel like this was such a rude comment and i...    anger   \n",
       "15999  i know a lot but i feel so stupid because i ca...  sadness   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0                                i didnt feel humiliated  \n",
       "1      i can go from feeling so hopeless to so damned...  \n",
       "2       im grabbing a minute to post i feel greedy wrong  \n",
       "3      i am ever feeling nostalgic about the fireplac...  \n",
       "4                                   i am feeling grouchy  \n",
       "...                                                  ...  \n",
       "15995  i just had a very brief time in the beanbag an...  \n",
       "15996  i am now turning and i feel pathetic that i am...  \n",
       "15997                     i feel strong and good overall  \n",
       "15998  i feel like this was such a rude comment and i...  \n",
       "15999  i know a lot but i feel so stupid because i ca...  \n",
       "\n",
       "[16000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to 'text' to clean it\n",
    "# Add cleaned data as a separate column to the DataFrame\n",
    "df_train['cleaned_text'] = df_train['Text'].apply(clean_text)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYiwo30_F5vn",
    "outputId": "1517258a-bff2-43f2-fefe-2b469228a102"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              i didnt feel humiliated\n",
       "1    i can go from feeling so hopeless to so damned...\n",
       "2     im grabbing a minute to post i feel greedy wrong\n",
       "3    i am ever feeling nostalgic about the fireplac...\n",
       "4                                 i am feeling grouchy\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"cleaned_text\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX0IPDbKF5vn"
   },
   "source": [
    "**Step-4:** Removing special charachters,extra space,and convert into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lhrm_XheF5vo"
   },
   "outputs": [],
   "source": [
    "features = df_train['cleaned_text']\n",
    "processed_features = []\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "    \n",
    "    # Remove single characters appearing in the text except the start\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "    \n",
    "    # Remove single characters appearing at the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "    \n",
    "    # Substitute multiple spaces with a single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "    \n",
    "    \n",
    "    # Convert to lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "\n",
    "    processed_features.append(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJMTWRP9F5vo",
    "outputId": "fcc8cd97-1325-40e1-f817-5919a2b65f6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       " 'im grabbing minute to post feel greedy wrong',\n",
       " 'i am ever feeling nostalgic about the fireplace will know that it is still on the property',\n",
       " 'i am feeling grouchy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first five values of processed data\n",
    "processed_features[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqQe-g67F5vp"
   },
   "source": [
    "**Step-5:** Saving the above processed data into processed_text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "V0wZ82ASF5vp",
    "outputId": "499085f7-5b4a-4b62-9b78-1a7f65be7158"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>im grabbing minute to post feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>i am feeling grouchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>i just had very brief time in the beanbag and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>i am now turning and feel pathetic that am sti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>i feel strong and good overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>i feel like this was such rude comment and im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>i know lot but feel so stupid because can not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Emotion  \\\n",
       "0                                i didnt feel humiliated  sadness   \n",
       "1      i can go from feeling so hopeless to so damned...  sadness   \n",
       "2       im grabbing a minute to post i feel greedy wrong    anger   \n",
       "3      i am ever feeling nostalgic about the fireplac...     love   \n",
       "4                                   i am feeling grouchy    anger   \n",
       "...                                                  ...      ...   \n",
       "15995  i just had a very brief time in the beanbag an...  sadness   \n",
       "15996  i am now turning and i feel pathetic that i am...  sadness   \n",
       "15997                     i feel strong and good overall      joy   \n",
       "15998  i feel like this was such a rude comment and i...    anger   \n",
       "15999  i know a lot but i feel so stupid because i ca...  sadness   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0                                i didnt feel humiliated   \n",
       "1      i can go from feeling so hopeless to so damned...   \n",
       "2       im grabbing a minute to post i feel greedy wrong   \n",
       "3      i am ever feeling nostalgic about the fireplac...   \n",
       "4                                   i am feeling grouchy   \n",
       "...                                                  ...   \n",
       "15995  i just had a very brief time in the beanbag an...   \n",
       "15996  i am now turning and i feel pathetic that i am...   \n",
       "15997                     i feel strong and good overall   \n",
       "15998  i feel like this was such a rude comment and i...   \n",
       "15999  i know a lot but i feel so stupid because i ca...   \n",
       "\n",
       "                                          processed_text  \n",
       "0                                i didnt feel humiliated  \n",
       "1      i can go from feeling so hopeless to so damned...  \n",
       "2           im grabbing minute to post feel greedy wrong  \n",
       "3      i am ever feeling nostalgic about the fireplac...  \n",
       "4                                   i am feeling grouchy  \n",
       "...                                                  ...  \n",
       "15995  i just had very brief time in the beanbag and ...  \n",
       "15996  i am now turning and feel pathetic that am sti...  \n",
       "15997                     i feel strong and good overall  \n",
       "15998  i feel like this was such rude comment and im ...  \n",
       "15999  i know lot but feel so stupid because can not ...  \n",
       "\n",
       "[16000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the processed data as a separate column to the DataFrame\n",
    "\n",
    "df_train['processed_text'] = processed_features\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xcIJ90fXF5vp"
   },
   "source": [
    "**Step-6:** Extracting processed_text and Emotion then creating final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "f0PjWX6-F5vq",
    "outputId": "74d3e437-6f24-44ca-8ac6-2f4544f1f4bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing minute to post feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had very brief time in the beanbag and ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and feel pathetic that am sti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such rude comment and im ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know lot but feel so stupid because can not ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          processed_text  Emotion\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2           im grabbing minute to post feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995  i just had very brief time in the beanbag and ...  sadness\n",
       "15996  i am now turning and feel pathetic that am sti...  sadness\n",
       "15997                     i feel strong and good overall      joy\n",
       "15998  i feel like this was such rude comment and im ...    anger\n",
       "15999  i know lot but feel so stupid because can not ...  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = df_train[[\"processed_text\",\"Emotion\"]]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC0_hS2oF5vq"
   },
   "source": [
    "**Step-7:** Generating tokens and doing vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PBC6hdsEF5vq"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text using TweetTokenizer from NLTK\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BlTqw1oSF5vr"
   },
   "outputs": [],
   "source": [
    "# Function to generate tokens using TweetTokenizer\n",
    "def tokenize(text): \n",
    "    tk = TweetTokenizer()\n",
    "    return tk.tokenize(text)\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word',tokenizer = tokenize,lowercase = True,ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R76lf62qF5vr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Generate unique words from the processed data by applying Count Vectorizer along with TweetTokenizer\n",
    "count= vectorizer.fit_transform(final_df['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VM_YnIYF5vr",
    "outputId": "ceeccd6d-fba0-4c24-8b10-0a32e83629cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 15206)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the shape of the data- Count vectorizer provides information about unique words present in data\n",
    "count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Xvx4aVBjF5vr"
   },
   "outputs": [],
   "source": [
    "# Load the libraries required for performing classification\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gps2u8hF5vr"
   },
   "source": [
    "**Step-8:** Spliting the data into training and testing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ruX8CT5RF5vs"
   },
   "outputs": [],
   "source": [
    "# Use processed data as independent variable and polarity as dependent variable\n",
    "\n",
    "X = final_df['processed_text'].values\n",
    "y = final_df['Emotion'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=100, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRbABa5YF5vs"
   },
   "source": [
    "**Step-9:** Doing vectorization for training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ns_veV1jF5vs"
   },
   "outputs": [],
   "source": [
    "# Extract features using TFIDF Vectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_idf = vectorizer.fit_transform(X_train)\n",
    "X_test_idf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "b1Bf8MXWF5vs",
    "outputId": "79a02a8e-1533-4658-cebb-822620f9153b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blah</th>\n",
       "      <td>7.758809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chest</th>\n",
       "      <td>7.684701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>7.433387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>7.379319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dream</th>\n",
       "      <td>7.379319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf_weights\n",
       "blah         7.758809\n",
       "chest        7.684701\n",
       "pregnant     7.433387\n",
       "computer     7.379319\n",
       "dream        7.379319"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print idf values\n",
    "df_idf = pd.DataFrame(vectorizer.idf_, index=vectorizer.get_feature_names_out(),columns=[\"idf_weights\"])\n",
    "# Sort ascending\n",
    "df_idf.sort_values(by=['idf_weights'],ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kT7ijSpF5vt"
   },
   "source": [
    "**Step-10:** Model building(generate asked model) and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpieU00GF5vt",
    "outputId": "c70703ef-08db-4a43-a87a-e0ef08fa7abc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Multinomial Naive Bayes Classification\n",
    "# Apply MultinomialNB on training data\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_idf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70jQsvjJF5vt",
    "outputId": "e0cd00ce-e193-4e3d-ebff-d07563c7d6fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy\n",
      "0  Multinomial Naive Bayes  0.740625\n"
     ]
    }
   ],
   "source": [
    "# Predict polarity by fitting the model to testing data\n",
    "pred_mnb = mnb.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy of predicted values\n",
    "acc = accuracy_score(y_test, pred_mnb)\n",
    "\n",
    "\n",
    "results = pd.DataFrame([['Multinomial Naive Bayes', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jh4i3tKNF5vt",
    "outputId": "f942e059-a898-4cad-e603-205ff3506037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy\n",
      "0  Multinomial Naive Bayes  0.740625\n",
      "1      Random Forest(Gini)  0.831667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3156\\1363590104.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(model_results, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "# Perform Random Forest classification on the processed data and compare the accuracy score of both these models\n",
    "\n",
    "# Random Forest Classifier with 'gini'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train_idf, y_train)\n",
    "\n",
    "# Predict using testing data\n",
    "y_pred_rf = clf_rf.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest(Gini)', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xX7wwZUNF5vu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3156\\4204601156.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(model_results, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with 'entropy'\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rf = RandomForestClassifier(criterion='entropy')\n",
    "clf_rf.fit(X_train_idf, y_train)\n",
    "\n",
    "# Predict using testing data\n",
    "y_pred_rf = clf_rf.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest(Entropy)', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2kg62kKF5vu",
    "outputId": "b3a1dad9-3c9e-42a5-a4e5-84aec2fad298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  Accuracy\n",
      "0  Multinomial Naive Bayes  0.740625\n",
      "1      Random Forest(Gini)  0.831667\n",
      "2   Random Forest(Entropy)  0.809167\n",
      "3              SVC by SVM   0.811667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3156\\2025736605.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(model_results, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "#svm model\n",
    "from sklearn.svm import SVC\n",
    "clf_svc = SVC()\n",
    "clf_rf.fit(X_train_idf, y_train)\n",
    "\n",
    "# Predict using testing data\n",
    "y_pred_rf = clf_rf.predict(X_test_idf)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "model_results = pd.DataFrame([['SVC by SVM ', acc]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U06xjADOF5vu",
    "outputId": "4e817ced-62dc-4bc0-8cab-26bea15d6649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 499,   15,   65,    4,   28,    0],\n",
       "       [  23,  448,   92,    5,   30,   17],\n",
       "       [  18,   11, 1465,   47,   52,   10],\n",
       "       [   4,    3,   83,  280,    3,    0],\n",
       "       [  39,   39,  225,   14, 1083,    7],\n",
       "       [   0,   39,   25,    0,    6,  121]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confusion matrix for Random Forest\n",
    "\n",
    "confusion_matrix(y_test,y_pred_rf) ### Confusion matrix for Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLdWf_KaEX-h"
   },
   "source": [
    "**Conclusion** : Random forrest classifier has performed the best."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_D47_DIY_Solution_V1_0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
